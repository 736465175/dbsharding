################分库分表笔记sql
create database `order_db` character set `utf8` collate `utf8_general_ci`;

drop table if exists `t_order_1`;
create table `t_order_1` (
	`order_id` bigint(20) not null comment '订单ID',
	`price` decimal(10,2) not null comment '订单价格',
	`user_id` bigint(20) not null comment '下单用户ID',
	`status` varchar(50) character set `utf8` collate `utf8_general_ci` not null comment '订单状态',
	primary key (`order_id`) using btree
) engine = innoDB character set = utf8 collate = utf8_general_ci row_format = dynamic;

drop table if exists `t_order_2`;
create table `t_order_2` (
	`order_id` bigint(20) not null comment '订单ID',
	`price` decimal(10,2) not null comment '订单价格',
	`user_id` bigint(20) not null comment '下单用户ID',
	`status` varchar(50) character set `utf8` collate `utf8_general_ci` not null comment '订单状态',
	primary key (`order_id`) using btree
) engine = innoDB character set = utf8 collate = utf8_general_ci row_format = dynamic;

create database `order_db_1` character set `utf8` collate `utf8_general_ci`;
create database `order_db_2` character set `utf8` collate `utf8_general_ci`;

******************************************************************************************************************


<!-- https://mvnrepository.com/artifact/org.apache.shardingsphere/sharding-jdbc-spring-boot-starter -->
<dependency>
    <groupId>org.apache.shardingsphere</groupId>
    <artifactId>sharding-jdbc-spring-boot-starter</artifactId>
    <version>4.1.1</version>
</dependency>

1.编写程序
    1.分片规则的配置：配置类容主要是
        数据源m1、
        主键生成策略、order_id，SNOWFLAKE
        配置数据节点、m1.t_order_$->{1..2}
        分片键和策略、order_id（是将数据库的表水平拆分的关键字段），algorithm-expression: t_order_$->{order_id % 2 +1}
2.启动报错：DruidDataSourceAutoConfigure.class Failed to determine a suitable driver class
    解决:
        DruidDataSourceAutoConfigure查看源码:
        1.表明druid是根据spring.datasource.druid找jdbc属性的，如果not found,则根据spring.datasource找jdbc属性，
        一般而言这是不会出现错误的。但是我这里使用了shardingjdbc
        2.就很显然了，他根据spring.datasource.druid或者spring.datasource确实找不到，因为我的结构是spring.shardingsphere.datasource
            解决方式1：
                如果我们用的jar包是druid-spring-boot-starter，则在启动类上排除druid自动配置
                @SpringBootApplication(exclude = {DruidDataSourceAutoConfigure.class})
            解决方式2：不用druid-spring-boot-starter,改为druid

3.使用@Configuration配置类配置分片规则时，程序会报错org.apache.shardingsphere.shardingjdbc.spring.boot.SpringBootConfiguration 数据源为空
    原因是sharding-jdbc读取分片规则配置时默认是从配置文件中读取配置：
        源码：
            @ConditionalOnProperty(
                prefix = "spring.shardingsphere",
                name = {"enabled"},
                havingValue = "true",
                matchIfMissing = true
            )
            @AutoConfigureBefore({DataSourceAutoConfiguration.class})
            public class SpringBootConfiguration implements EnvironmentAware {...}
    解决方案就是在启动类中过滤掉这个类 exclude=SpringBootConfiguration.class

4.绑定表：指分片规则一致的主表和子表，例如t_order表和t_order_item表，均按照order_id分片，即分片键也相同；否则会出现关联查询的笛卡尔积
5.广播表：所有的分片数据源中都存在的表，表结构和数据在每个库完全一致，
    适用于数据量不大且需要与海量数据的表进行关联查询的场景，如字典表
6.分片算法：
    通过分片算法将数据分片，支持=、BETWEEN、IN分片；由开发者自行实现，包括精确分片算法、范围分片算法、复合分片算法等。
        where order_id between ? and ? 将采用范围分片算法，复合分片算法适合分片键有多个复杂情况。
7.分片策略：内置的分片策略大致可以分为：尾数取模、哈希、范围、标签、时间等
    取模方式弊端：在新增或者减少分片表(数据节点)数量的时候旧数据如何处理？

8.SQL解析：
    《SQL解析->查询优化->SQL路由->SQL改写->SQL执行->结果归并》
    1.SQL解析：过程分为词法解析和语法解析，词法解析器用于将SQL拆解为不可再分的原子符号，称为Token。
        并根据不同的数据库方言所提供的字典，将其归类为关键字、表达式、字面量、和操作符。
        再使用语法解析器将SQL转换成抽象语法树。
        最后再对抽象的语法树遍历提炼出分片所需的 上下文，并标记有可能需要 SQL改写 的位置
    2.SQL路由：就是把针对 逻辑表 的数据操作映射到对 数据节点 操作的过程。
        根据解析上下文匹配数据库和 表的分区策略，并生成路由路径。对于携带分片键的SQL，根据分片键操作符不同可以
        划分为单片路由(分片键的操作符是等号)、多片路由(分片键的操作符是IN)和范围路由(分片键的操作符是BETWEEN)，
        不携带分片键的SQL则采用广播路由。根据分片键进行路由的场景可分为直接路由、标准路由、笛卡尔路由等
        2.1标准路由：
            是Sharding-jdbc最推荐使用的分片方式。它适用范围是 不包含关联查询 或 仅包含绑定表之间关联查询的SQL。
            当分片运算符是=，路由结果落入单库(表)，当分片运算符是BETWEEN或者IN时，路由结果不一定落入单库(表)；
            因此一条逻辑SQL最终可能被拆分为多条SQL执行。
    3.SQL改写：
        1.面向逻辑表书写的SQL，并不能够直接在真实的数据库中执行，SQL改写用于将逻辑SQL 改写为在真实数据库中可以正确
            执行的SQL
        2.分组、排序、分页查询时，SQL改写 可能会进行补列、修改查询条件等
    4.SQL执行：
        Sharding-jdbc采用一套自动化的执行引擎，负责将路由和改写完成之后的真实SQL安全且高效发送到底层数据源执行。
        不是简单的将SQL通过JDBC直接连接数据源执行，也不是直接将执行请求放入线程池并发执行；它更关注平衡数据源连接的
        创建以及内存占用所产生的消耗，以及最大限度合理利用并发等；目标是自动化平衡资源控制与执行效率，可以在如下两种
        模式自适应切换：
            1.内存限制模式：前提是连接数没限制时，多线程并发执行。（适用于OLAP<联机分析处理>操作，实现效率最大化）
            2.连接限制模式：严格控制一次操作耗费的连接数量，创建唯一数据库连接，串行执行，如果分片散落在不同数据库，
                每个库只创建一个连接。(适用于 联机事务处理OLTP操作，一个连接串行执行保证事务)
    5.结果归并：
        1.将从各个数据节点获取的数据结果集，组合为一个结果集并正确的返回至请求客户端。
        2.支持的结果归并从功能上分为：遍历、排序、分组、分页、聚合；他们是组合而非互斥的关系。
        3.结果归并从结构划分为：流式归并、内存归并、装饰者归并。流式归并和内存归并是互斥的，装饰者归并可以在流式归并、
            内存归并之上做进一步处理。
        4.内存归并：将所有分片结果集的数据遍历并存储在内存中，再通过统一分组、排序、聚合等计算之后，再将其封装成逐条
            访问的数据结果集返回。
        5.流式归并：每一次从数据库结果集中获取到的数据，都能够通过游标逐条获取的方式返回正确的单条数据，与数据库原生
            的返回结果集的方式最契合。(推荐使用，一边处理一边归并，不占用太多内存，性能低点)
            例如：先查询每个数据节点并排序，每个结果集分配一个游标，逐条比较出最大/最小值，取到值的游标加1，继续重复
                比较；最终将所有数据集顺序排成一个数据集的顺序。
        6.装饰者归并：
            是对所有的结果集归并进行统一的功能增强，比如归并时需要聚合(SUM)，在进行聚合计算前，都会通过内存归并或
                流式归并查询出结果集。这个聚合归并是在之前归并之上追加的，即装饰者模式。

9.总结：
    1.概念：逻辑表、真实表、数据节点、绑定表、广播表、分片键、分片算法、分片策略、主键生成策略
    2.核心功能：数据分片、读写分离、分布式事务？
    3.执行流程：SQL解析->查询优化->SQL路由->SQL改写->SQL执行->结果归并


10.水平分库：
    把同一个表的数据按照一定规则拆到不同的数据库相同的表中，每个库可以放在不同的服务器上。就需要配置分库策略
    create database `order_db_1` character set `utf8` collate `utf8_general_ci`;
    create database `order_db_2` character set `utf8` collate `utf8_general_ci`;
    分库策略配置参考yml




























